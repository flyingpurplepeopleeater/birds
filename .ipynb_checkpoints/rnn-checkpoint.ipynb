{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "505f14c7-e0aa-471e-bcff-f25c9e0a1ecd",
   "metadata": {},
   "source": [
    "<h1>Bird Network</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1a469b-95e1-410c-9e5c-a2cae094be2f",
   "metadata": {},
   "source": [
    "Let's start with one year of data; our 2019 data; we're going to have all of the weather data and bird data\n",
    "Our input (for the one-year run) will be just weather and number of birds\n",
    "Except that we also want the weather data for the day of\n",
    "Let's first figure out how to do it and then figure out how to get the data in the form that will let us do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aacaaef-38af-439c-a5f7-9754afaaf87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a white background\n",
    "set_style(\"whitegrid\")\n",
    "\n",
    "## Import all the keras stuff we'll need\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88100a97-c081-4e70-bdcb-2c67c699bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the model\n",
    "# Warning is no problem\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.SimpleRNN(30, input_shape=(30,6), return_sequences=False))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='relu'))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=\"mae\",\n",
    "                 metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dff317-aa57-473c-8be8-85f88643e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's get our data\n",
    "# We split our 7 years of information into 30 day windows, with first-elements 15 days apart to avoid overfitting\n",
    "\n",
    "import datetime\n",
    "\n",
    "def diff(row):\n",
    "    return (datetime.date(int(row[\"YEAR\"]),int(row[\"MONTH\"]),int(row[\"DAY\"])) - datetime.date(2017,1,1)).days\n",
    "\n",
    "def diffmod(row):\n",
    "    return (datetime.date(int(row[\"YEAR\"]),int(row[\"MONTH\"]),int(row[\"DAY\"])) - datetime.date(int(row[\"YEAR\"]),1,1)).days\n",
    "\n",
    "df = pd.read_csv(\"Data/AllSpecYear.csv\")\n",
    "df = df[df[\"LATITUDE\"]==36]\n",
    "df = df[df[\"LONGITUDE\"]==-86]\n",
    "df[\"T\"] = df.apply(diff,axis=1)\n",
    "df[\"DOY\"] = df.apply(diffmod,axis=1)\n",
    "df = df.sort_values(\"T\")[[\"OBSERVATION COUNT\",\"PRCP\",\"SNOW\",\"TMAX\",\"DOY\",\"SPECIES\",\"T\"]]\n",
    "df = df[[\"OBSERVATION COUNT\",\"PRCP\",\"SNOW\",\"TMAX\",\"DOY\",\"SPECIES\",\"T\"]]\n",
    "df=df[df[\"SPECIES\"]==0]\n",
    "array = df.drop(\"T\",axis=1).to_numpy()\n",
    "Xarray = np.empty((int((len(array)-30)/15+1),30,6))\n",
    "Yarray = np.array([])\n",
    "for i in range(len(array)-30):\n",
    "    if i%15==0:\n",
    "        for j in range(30):\n",
    "            Xarray[int(i/15)][j] = array[i+j]\n",
    "        Yarray = np.append(Yarray,[array[i+30][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c2c7a-2bd5-4054-9a4d-7ebe4d5a12d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making our splits\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xarray, Yarray,\n",
    "                                                       shuffle = True,\n",
    "                                                       random_state = 440,\n",
    "                                                       test_size = .2)\n",
    "X_train_train,X_val,y_train_train,y_val = train_test_split(X_train, y_train,\n",
    "                                                           test_size=.2,\n",
    "                                                           shuffle=True,\n",
    "                                                           random_state=440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69241aa3-e89e-43fe-b2ba-1616f8517ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(X_train_train, y_train_train,\n",
    "                    epochs = epochs,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(X_val,y_val))\n",
    "\n",
    "## Note training this model can take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d104327d-f620-4ec1-bb22-856e829a9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some accuracy information\n",
    "\n",
    "history_dict = history.history\n",
    "## Plotting the training and validation accuracy\n",
    "plt.figure(figsize = (8,6))\n",
    "\n",
    "plt.scatter(range(1,epochs+1), history_dict['mae'], label = \"Training Accuracy\")\n",
    "plt.scatter(range(1,epochs+1), history_dict['val_mae'], label = \"Validation Set Accuracy\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b964e4-e8e8-4f73-b009-13a3774a3611",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the training and validation loss\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "\n",
    "plt.scatter(range(1,epochs+1), history_dict['loss'], label = \"Training Loss\")\n",
    "plt.scatter(range(1,epochs+1), history_dict['val_loss'], label = \"Validation Set Loss\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=12)\n",
    "plt.ylabel(\"Loss Function Value\", fontsize=12)\n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de99e99-79d7-4343-8752-cb9b45866a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
